---
layout: post
title: Bayesian Network 요약
date: 2021-05-27
#categories: [Bayesian]
#tag: [causal-inference, bayesian, DAG, probability, gaussian-bayesian-network,data-analysis]
comments: true
---

Bayesian network modelling은 크게 2가지의 category로 나눌 수 있다. 

* **Discrete Bayesian networks**: global과 local distributions이 multinomia으로 가정되는 경우 사용된다. association measures로 사용되는 방법은  mutual information (log-likelihood ratio) and
Pearson’s X2이다. 

* **Gaussian Bayesian networks**: global distribution is multivariate normal이고  local distributions are univariate normals linked by linear dependence relationships. Association is measured by various estimators of Pearson’s correlation.



Gaussian Bayesian networks

* 우선 Gaussian Bayesian Network는 노드가 정규분포를 따를 때 쓸 수 있는 방법입니다.

* 그리고 parents가 없는 node즉, root node는 marginal distributions로 설명된다. 

* 각 each node has a variance that is specific to that node and does not depend on the values of the parents

* 각 node의 local distribution은 intercept을 포함하고 interaction term이 없는 Gaussian linear model로 표현될 수 있다. 


먼저, 쉬운 **2. 모수 추정** 방법에 대해 먼저 설명드리겠습니다.
GBN은 $i$번째 노드인 $X_i$가 local하게 정규분포를 따른다 가정합니다.

   $$
   X_{i}=\mu_{X_{i}}+\Pi_{X_{i}} \boldsymbol{\beta}_{X_{i}}+\varepsilon_{X_{i}}, \quad \varepsilon_{X_{i}} \sim N\left(0, \sigma_{X_{i}}^{2}\right)
   $$


만약에 the amount of data is not enough to induce a high scoring network.
해결책으로 Efron's Bootstrap a� a compu­ tationally efficient approach for answering these questions. 

네트워크를 더 높은 score로 얻기 위해서는 when learning structure, we can use prior knowledge on the structures we are searching to reduce the �ize of the search space, and thus improve both the speed of mducuon and more importantly, the quality of the learned network. Commonly used prior information include order­ ing constraints on the random variables, or the existence of certain arcs. 즉, constrain the search process을 주는 것이다.

## 생물학적 데이터 적용의 문제점

* 일반적으로 small sizes of available data sets (n  p) sample size increases, the information present in
the data dominates the information provided in the prior and determines the overall behaviour of the model. For small sample sizes:



* 과연  discrete and Gaussian assumptions really sensible for these kinds of data 즉, Gene expression data are modelled as continuous random variables either assuming a Gaussian distribution or applying results from robust statistics.

* batch effects introduced by the instruments and the chemical reactions used in collecting the data.

---
## 해결법

 Inference procedures are
usually unable to identify a single best BN, settling instead on a set
of equally well behaved models. For this reason, it is important to
incorporate prior biological knowledge into the network through the
use of informative priors

the prior distribution plays a much larger role because there is
not enough data available to disprove the assumptions the prior
encodes;


![](/images/feature_selected.png){: width = "400", height="300"}

그리고 for sequence data, we aim to find the subset of genes

---
## bootstrapping

sample size가충분히 large 하면 문제가 없지만
특히, for small training sets we can find slightly better scoring networks using the constraints generated by the bootstrap.
(non-parametric) bootstrap that doesn't make any distributional assumptions
하지만 If you are provided with small sample size (as a sidelight, what is "small" seems to depend on some underlying customary rule in each research field), no bootstrap will do the magic.
예를들어 Assuming a database contains three observations for each of the two variables under investigation, no inference will make sense.

Bootstrap works well in small sample sizes by ensuring the correctness of tests (e.g. that the nominal 0.05 significance level is close to the actual size of the test), however the bootstrap does not magically grant you extra power. If you have a small sample, you have little power, end of story.

For prediction, bootstrapping will give you better (more honest) estimates of internal validity than split sample validation.


과연 constraint-based와 score-based algorithms중에 어떤 방법이 더 accurate structural reconstruction할 것인가?

그리고 e hybrid algorithms more accurate than constraint-based 또는score-based algorithms

Constraint-based algorithms은 conditional independence constraints을 statistical tests로 찾는 방법이다.

Score-based algorithms은 여러 DAG을 생성한 다음 가장 큰 network score을 찾는 방법이다.

Hybrid algorithms은 constraint-based을 우선 사용해서 DAGs 후보들의 space를 줄이고 나서 score-based strategy로 가장 큰 score를 찾는 방법이다.   




데이타 타입

Discrete Bayesian Networks와 Gaussian Bayesian Networks로 나눌 수 있다. 

평가 
The metrics that measure structural discrepancies between graphs generally produce a score
that corresponds to some difference between the learnt graph and the ground truth graph.
One of the most commonly used metrics in this field of research is the Structural Hamming
Distance (SHD) proposed by Tsamardinos et al (2006). The SHD score represents the
minimum number of edge insertions, deletions, and arc reversals needed to convert the learnt
graph into the true graph. It turns out that
𝑆𝐻𝐷 = 𝐹𝑁 + 𝐹𝑃 (3)
where arc reversals fall either under 𝐹𝑁 or 𝐹𝑃.


우선 Discrete networks에서는score-based algorithms often have higher SHDs for small samples

constraint-based algorithms have better SHD than score-based algorithms for small sample sizes

Gaussian networks에서는 tabu search and simulated annealing have larger SHDs than
constraint-based or hybrid algorithms for most samples;
• hybrid and constraint-based algorithms have roughly the same SHD
for all sample sizes.

결론은 constraint-based algorithms are more accurate than score-based algorithms for small sample sizes
그리고 accuracy를 비교하자면 s hybrid algorithms이 딱히 뛰어나지 않았다. 


Bayesian network는 (G, $\theta$)로 되어 있다. G는 directed acyclic graph를 말하고  data set D with n observations으로 구성되어 있다. 


$\theta$는 network를 구성하는parameters set을 말한다.

You can use $$\LaTeX$$ to typeset formulas. A formula can be displayed inline, e.g. $$e=mc^2$$, or as a block:
$$\int_\Omega \nabla u \cdot \nabla v~dx = \int_\Omega fv~dx$$
Also check out this [LaTeX introduction](https://en.wikibooks.org/wiki/LaTeX/Mathematics).

출처: Data Analysis with Bayesian Networks: A Bootstrap Approach
Who Learns Better Bayesian Network Structures Constraint-Based, Score-based or Hybrid Algorithms?
https://stats.stackexchange.com/questions/112147/can-bootstrap-be-seen-as-a-cure-for-the-small-sample-size
https://www.bnlearn.com/examples/

