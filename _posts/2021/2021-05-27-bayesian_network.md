---
layout: post
title: Bayesian Network 요약
date: 2021-05-27
#categories: [Bayesian]
#tag: [causal-inference, bayesian, DAG, probability, gaussian-bayesian-network,data-analysis]
comments: true
output: 
  html_document:
    toc: true
    toc_depth: 4
    toc_float: true
    code_folding: hide
---


이번 post는 **Gene regulatory network (GRN)**를 modeling에서 **Bayesian network (BN)**이 어떻게 적용되는지에 대해서 간단하게 요약해 보았다.

일반적으로 Bulk data의 GRN을 위해서 사용되는 방법은 BN 외에도 주로 correlation, regression, ordinary differential equations (ODEs), mutual information (MI), Gaussian graphical models 그리고 BN이다. 각각의 방법들은 아래와 같이 서로 다른 pros and cons가 있다.  

* correlation-based method는 assumptions에 dependent하지 않고 computationally efficient하다는 장점이 있다. 그리고 비슷한 functions 또는 regulation되는 group genes을 찾는데 용이하다. 반면 directionality를 알 수 없고 다른 information의 integration을 통해 interpretability를 높일 수가 없다. (WGCNA)

* Regression-based method는 linear cascades에 대해서는 잘 modeling을 하지만 feed-forward loops에 대해서는 그렇지 못하다. (GENIE3)

* MI 방식은 genes의 pairs간의 degree of dependencies에 의해서 network structure가 결정된다. directionality와 potential causality를 잘 추론할 수 있고 Regression-based method과 반대로 feed-forward loops에 대해서 높은 정확도를 나타내고 반면 linear cascades에 대해서는 limited performance를 나타낸다. 

* BN 방식은 prior information을 integration하기가 용이하고 causal/directional gene–gene interactions을 추론할 수가 있다. 단점으로는 higher computation cost와 optimal topology를 찾는 확률이 조금 떨어진다. 다른 방식의 표현으로 large p & small n problem으로 structure learning시의 genes의 숫자가 너무 많은 NP-hard의 문제에 직면하기에 다른 방법들과 비교해서 적은 수의 small networks를 구성할 수밖에 없다.     


---

## BN 카테고리

Bayesian network modelling은 크게 2가지의 category로 나눌 수 있다. 

* **Discrete Bayesian networks**: global과 local distributions이 multinomia으로 가정되는 경우 사용된다. association measures로 사용되는 방법은  mutual information (log-likelihood ratio) and
Pearson’s X2이다. 

* **Gaussian Bayesian networks**: global distribution is multivariate normal이고 local distributions이 univariate normals이여서 global과 local이 linear dependence relationships 연결되어 있는 경우 사용한다. Association은 Pearson’s correlation이 사용된다.


Gaussian Bayesian networks

* 우선 Gaussian Bayesian Network는 노드가 정규분포를 따를 때 쓸 수 있는 방법입니다.

* 그리고 parents가 없는 node즉, root node는 marginal distributions로 설명된다. 

* 각 each node has a variance that is specific to that node and does not depend on the values of the parents

* 각 node의 local distribution은 intercept을 포함하고 interaction term이 없는 Gaussian linear model로 표현될 수 있다. 


## 생물학적 데이터 적용의 문제점

sample size가충분히 large 하면 문제가 없지만 일반적으로 데이터의 양이 부족해서 (small sizes of available data sets) high scoring network 얻기 힘들다. 

결국에는 제공된 information에 의해서 지배되고 model을 전반적으로 결정한다. 

* 과연  discrete and Gaussian assumptions이 이러한 data에 잘 적용이 될 것인가하는 의문이 든다. 

* batch effects이 있을 수 있다.

## 해결법

해결책으로 **Bootstrapping**이 computationally 효과적인 approach이다. 

다른방법으로는 prior biological knowledge를 통해서 search space의 size를 줄이고 learning structure를 향상시킬 수 있다.

방법으로 random variables에 대해서 ordering constraints을 주거나 certain arc에 대해서 미리 정보를 주는 것이다. 즉,  search process에 constrain을 주는 것이다. 

* 그리고 마지막으로 genes의 subset으로만 모델링을 진행하는 것이다.


![](/images/feature_selected.png){: width = "500", height="400"}


## bootstrapping

bootstrap (non-parametric)은 아무런 distributional assumptions이 없다. 





sample size가충분히 large 하면 문제가 없지만



small training sets에서는 bootstrap에 의한 constraints scoring networks가 더 우수한 것으로 알려져 있다. 


특히, for small training sets we can find slightly better scoring networks using the constraints generated by the bootstrap.
하지만 If you are provided with small sample size (as a sidelight, what is "small" seems to depend on some underlying customary rule in each research field), no bootstrap will do the magic.
예를들어 Assuming a database contains three observations for each of the two variables under investigation, no inference will make sense.

Bootstrap works well in small sample sizes by ensuring the correctness of tests (e.g. that the nominal 0.05 significance level is close to the actual size of the test), however the bootstrap does not magically grant you extra power. If you have a small sample, you have little power, end of story.

For prediction, bootstrapping will give you better (more honest) estimates of internal validity than split sample validation.


과연 constraint-based와 score-based algorithms중에 어떤 방법이 더 accurate structural reconstruction할 것인가?

그리고 e hybrid algorithms more accurate than constraint-based 또는score-based algorithms

Constraint-based algorithms은 conditional independence constraints을 statistical tests로 찾는 방법이다.

Score-based algorithms은 여러 DAG을 생성한 다음 가장 큰 network score을 찾는 방법이다.

Hybrid algorithms은 constraint-based을 우선 사용해서 DAGs 후보들의 space를 줄이고 나서 score-based strategy로 가장 큰 score를 찾는 방법이다.   

* 과연  discrete and Gaussian assumptions really sensible for these kinds of data 즉, Gene expression data are modelled as continuous random variables either assuming a Gaussian distribution or applying results from robust statistics.


## The constraint-based approach
use statistical or information measures to test the conditional independence (CI) between variables. These methods rely heavily on the threshold selected for CI tests. High-order CI tests using large condition sets may be unreliable with the limitation of data size.

## score approach
traverse all possible structures using certain search algorithms to find the optimal one that maximizes the scoring function. In addition, prior knowledge can be easily incorporated into the model through the prior probability term in the scoring function. The search methods are heuristic and do not guarantee global optimal in most cases in consideration of large search space.


데이타 타입

Discrete Bayesian Networks와 Gaussian Bayesian Networks로 나눌 수 있다. 

평가 
The metrics that measure structural discrepancies between graphs generally produce a score
that corresponds to some difference between the learnt graph and the ground truth graph.
One of the most commonly used metrics in this field of research is the Structural Hamming
Distance (SHD) proposed by Tsamardinos et al (2006). The SHD score represents the
minimum number of edge insertions, deletions, and arc reversals needed to convert the learnt
graph into the true graph. It turns out that
𝑆𝐻𝐷 = 𝐹𝑁 + 𝐹𝑃 (3)
where arc reversals fall either under 𝐹𝑁 or 𝐹𝑃.


* 과연  discrete and Gaussian assumptions really sensible for these kinds of data 즉, Gene expression data are modelled as continuous random variables either assuming a Gaussian distribution or applying results from robust statistics.

우선 Discrete networks에서는score-based algorithms often have higher SHDs for small samples

constraint-based algorithms have better SHD than score-based algorithms for small sample sizes

Gaussian networks에서는 tabu search and simulated annealing have larger SHDs than
constraint-based or hybrid algorithms for most samples;
• hybrid and constraint-based algorithms have roughly the same SHD
for all sample sizes.

결론은 constraint-based algorithms are more accurate than score-based algorithms for small sample sizes
그리고 accuracy를 비교하자면 s hybrid algorithms이 딱히 뛰어나지 않았다. 


Bayesian network는 (G, $\theta$)로 되어 있다. G는 directed acyclic graph를 말하고  data set D with n observations으로 구성되어 있다. 


$\theta$는 network를 구성하는parameters set을 말한다.

You can use $$\LaTeX$$ to typeset formulas. A formula can be displayed inline, e.g. $$e=mc^2$$, or as a block:
$$\int_\Omega \nabla u \cdot \nabla v~dx = \int_\Omega fv~dx$$
Also check out this [LaTeX introduction](https://en.wikibooks.org/wiki/LaTeX/Mathematics).

출처: Data Analysis with Bayesian Networks: A Bootstrap Approach
Who Learns Better Bayesian Network Structures Constraint-Based, Score-based or Hybrid Algorithms?
https://stats.stackexchange.com/questions/112147/can-bootstrap-be-seen-as-a-cure-for-the-small-sample-size
https://www.bnlearn.com/examples/

