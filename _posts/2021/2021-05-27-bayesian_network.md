만약에 the amount of data is not enough to induce a high scoring network.
해결책으로 Efron's Bootstrap a� a compu­ tationally efficient approach for answering these questions. 

네트워크를 더 높은 score로 얻기 위해서는 when learning structure, we can use prior knowledge on the structures we are searching to reduce the �ize of the search space, and thus improve both the speed of mducuon and more importantly, the quality of the learned network. Commonly used prior information include order­ ing constraints on the random variables, or the existence of certain arcs. 즉, constrain the search process을 주는 것이다.

특히, for small training sets we can find slightly better scoring networks using the constraints generated by the bootstrap.

Bayesian network는 (G, $\theta$)로 되어 있다. G는 directed acyclic graph를 말하고 $\theta$는 network를 구성하는parameters set을 말한다.

You can use $$\LaTeX$$ to typeset formulas. A formula can be displayed inline, e.g. $$e=mc^2$$, or as a block:
$$\int_\Omega \nabla u \cdot \nabla v~dx = \int_\Omega fv~dx$$
Also check out this [LaTeX introduction](https://en.wikibooks.org/wiki/LaTeX/Mathematics).

출처: Data Analysis with Bayesian Networks: A Bootstrap Approach

